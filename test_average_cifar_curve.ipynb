{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63AdND1NRlag"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "wAGb-_-wRlaj"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import cifar10  #\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
        "import keras.utils as np_utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### import pre-computed curvatures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "sU4pnh68jVcp"
      },
      "outputs": [],
      "source": [
        "with open(f'cifar_output_curv_AVG', 'rb') as file:\n",
        "  output_curvatures = np.array(pickle.load(file))\n",
        "\n",
        "with open(f'cifar_input_curv', 'rb') as file:\n",
        "  input_curvatures = pickle.load(file)\n",
        "\n",
        "del file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbj_6JYSRlal"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "SpkBZcRVRlbM"
      },
      "outputs": [],
      "source": [
        "def shuffle_data(X: np.ndarray, Y: np.ndarray, seed: int):\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(X)\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4ANFhO7IRlbk"
      },
      "outputs": [],
      "source": [
        "def create_cifar_model():\n",
        "  return Sequential([\n",
        "    Conv2D(32, 3, padding='same', input_shape=cifar_X_train.shape[1:], activation='relu'),\n",
        "    Conv2D(32, 3, activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    Conv2D(64, 3, activation='relu'),\n",
        "    MaxPooling2D(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(10, activation='softmax'),\n",
        "  ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yH3wAymMRlbN"
      },
      "outputs": [],
      "source": [
        "def get_reduced_datasets(data_size: int, X: np.ndarray, Y: np.ndarray, order_method: str, curvature_set='input'):\n",
        "\n",
        "  _input_curvatures = input_curvatures\n",
        "  _output_curvatures = output_curvatures\n",
        "  _train_y = cifar_train_y[:, 0]\n",
        "\n",
        "  _curvature_set = _input_curvatures if curvature_set == 'input' else _output_curvatures\n",
        "\n",
        "  for y_class in range(10):\n",
        "    class_indices = _train_y == y_class\n",
        "    keep_indices = None\n",
        "    if order_method == 'random':\n",
        "      keep_indices = np.random.choice(X[class_indices].shape[0], data_size, replace=True)\n",
        "    elif order_method == 'low_to_high':\n",
        "      keep_indices = np.argsort(_curvature_set[y_class][:, 0])[:data_size]\n",
        "    elif order_method == 'high_to_low':\n",
        "      keep_indices = np.argsort(_curvature_set[y_class])[-data_size:]\n",
        "    elif order_method == 'mid':\n",
        "      num_low_curv = data_size // 2\n",
        "      num_high_curv = data_size - num_low_curv\n",
        "\n",
        "      curv_midpoint = _curvature_set[y_class][:, 0].shape[0] // 2\n",
        "\n",
        "      keep_indices = np.argsort(_curvature_set[y_class])[curv_midpoint - num_low_curv : curv_midpoint + num_high_curv]\n",
        "    elif order_method == 'ratio_low_to_high':\n",
        "      ratios = _output_curvatures[y_class][:, 0] / _input_curvatures[y_class][:, 0]\n",
        "      keep_indices = np.argsort(ratios)[:data_size]\n",
        "    elif order_method == 'ratio_high_to_low':\n",
        "      ratios = _output_curvatures[y_class][:, 0] / _input_curvatures[y_class][:, 0]\n",
        "      keep_indices = np.argsort(ratios)[-data_size:]\n",
        "    else:\n",
        "      raise ValueError(f\"order method not implemented: {order_method}\")\n",
        "\n",
        "    new_x_row = X[class_indices][keep_indices]\n",
        "    new_y_row = Y[class_indices][keep_indices]\n",
        "\n",
        "    del keep_indices\n",
        "\n",
        "    Reduced_X = np.vstack([Reduced_X, new_x_row]) if y_class > 0 else new_x_row\n",
        "    Reduced_Y = np.vstack([Reduced_Y, new_y_row]) if y_class > 0 else new_y_row\n",
        "\n",
        "  return Reduced_X, Reduced_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "UkYaHWwDRlbN"
      },
      "outputs": [],
      "source": [
        "def get_accuracies(X_train, Y_train, X_test, Y_test, order_method='low_to_high', curvature_set='input', num_models=5, shuffle_seed=None):\n",
        "  valacclist = []\n",
        "  acclist = []\n",
        "  for data_size in datasizes:\n",
        "    Reduced_X_train, Reduced_Y_train = get_reduced_datasets(data_size, X_train, Y_train, order_method, curvature_set)\n",
        "    print(f'ReducedX.shape: {Reduced_X_train.shape}')\n",
        "\n",
        "    if shuffle_seed is not None:\n",
        "      shuffle_data(Reduced_X_train, Reduced_Y_train, shuffle_seed)\n",
        "\n",
        "    valacclist.append([])\n",
        "    acclist.append([])\n",
        "    for _ in range(num_models):\n",
        "      nt = create_cifar_model()\n",
        "      nt.compile(loss= tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['categorical_accuracy'])\n",
        "      history  = nt.fit(Reduced_X_train, Reduced_Y_train, epochs=20, validation_data=(X_test, Y_test), verbose=0, batch_size = 128)\n",
        "      del nt\n",
        "      print(f\"  train acc = {history.history['categorical_accuracy'][-1]} val acc = {history.history['val_categorical_accuracy'][-1]}\")\n",
        "      valacclist[-1].append(history.history['val_categorical_accuracy'][-1])\n",
        "      acclist[-1].append(history.history['categorical_accuracy'][-1])\n",
        "      del history\n",
        "\n",
        "    del Reduced_X_train, Reduced_Y_train\n",
        "  return valacclist, acclist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "JaGTgrgxRlbO"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(accuracies, names=None):\n",
        "  plt.figure(figsize=(14, 10))\n",
        "  for acclist in accuracies:\n",
        "    plt.plot(datasizes, np.mean(acclist, axis=1))\n",
        "\n",
        "  if names is not None:\n",
        "    plt.legend(names, fontsize=11)\n",
        "\n",
        "  plt.xscale('log')\n",
        "  plt.gca().invert_xaxis()\n",
        "  plt.grid()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJIwSMMsRlbi"
      },
      "source": [
        "# cifar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "WySENwtxRlbi"
      },
      "outputs": [],
      "source": [
        "(cifar_X_train, cifar_train_y), (cifar_X_test, cifar_test_y) = cifar10.load_data()\n",
        "cifar_X_train = cifar_X_train / 255\n",
        "cifar_X_test = cifar_X_test/ 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ARaUR8vmRlbj"
      },
      "outputs": [],
      "source": [
        "cifar_Y_train = np_utils.to_categorical(cifar_train_y, 10)\n",
        "cifar_Y_test = np_utils.to_categorical(cifar_test_y, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZTeYGGrRlbd"
      },
      "source": [
        "### fine grain analysis on best performers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9H2HxsjARlbd"
      },
      "outputs": [],
      "source": [
        "datasizes = np.linspace(50000, 30000, 15).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[5000 3773 2848 2149 1622 1224  923  697  526  397]\n"
          ]
        }
      ],
      "source": [
        "print(datasizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[50000 48571 47142 45714 44285 42857 41428 40000 38571 37142 35714 34285\n",
            " 32857 31428 30000]\n"
          ]
        }
      ],
      "source": [
        "print(datasizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzwnA_SPJVPp"
      },
      "outputs": [],
      "source": [
        "rand, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='random', num_models=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQZiMfRIJfJG",
        "outputId": "3385cd76-6c6a-4f1f-9bfd-79cb3241f5cc"
      },
      "outputs": [],
      "source": [
        "high, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='high_to_low', curvature_set='output', shuffle_seed=1337, num_models=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jK7pmUSOJf82"
      },
      "outputs": [],
      "source": [
        "ratio_low, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_low_to_high', shuffle_seed=1337, num_models=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y2jVoqSvJhZU"
      },
      "outputs": [],
      "source": [
        "ratio_high, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_high_to_low', shuffle_seed=1337, num_models=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjA8vFVZJi2U"
      },
      "outputs": [],
      "source": [
        "namelist = ['Random selection', 'Highest Curvatures', 'Low Output/Input Ratio', 'High Output/Input Ratio']\n",
        "plot_accuracies([rand, high, ratio_low, ratio_high], namelist)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cgNNFOvLRlbd"
      },
      "source": [
        "### close up on ratio tests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu7GtXLqRlbe"
      },
      "outputs": [],
      "source": [
        "namelist = ['Random selection', 'Low Output/Input Ratio', 'High Output/Input Ratio']\n",
        "datasizes = np.logspace(3.699, 2.599, 20).astype('int')\n",
        "\n",
        "rand, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='random', num_models=15)\n",
        "ratio_low, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_low_to_high', shuffle_seed=1337, num_models=15)\n",
        "ratio_high, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_high_to_low', shuffle_seed=1337, num_models=15)\n",
        "\n",
        "plot_accuracies([rand, ratio_low, ratio_high], namelist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ph3i8P2fRlbe"
      },
      "outputs": [],
      "source": [
        "plot_accuracies([rand, ratio_low, ratio_high], namelist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ShvZHAW8Rlbn"
      },
      "outputs": [],
      "source": [
        "# these take a while to train, so I'm breaking them into their own cells to avoid retraining all of them if changes need to be mande to just one\n",
        "rand, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JC6jI5ccRlbn"
      },
      "outputs": [],
      "source": [
        "hess, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='hessian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z39cvo-pRlbo"
      },
      "outputs": [],
      "source": [
        "keep_high, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='high_to_low', curvature_set='output')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MtWMdlURlbo"
      },
      "outputs": [],
      "source": [
        "plot_accuracies([rand, hess, keep_high], ['rand', 'hess', 'keep_high'])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
