{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnet import ResNet34, ResNet\n",
    "import torch\n",
    "import math\n",
    "model = ResNet34(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_weights(model: ResNet):\n",
    "\tprint(model)\n",
    "\tif hasattr(model, 'reset_parameters'):\n",
    "\t\t\tprint('has attribute')\n",
    "\t\t\tmodel.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = torch.jit.load('models/model_scripted.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_scripted_module_parameters(scripted_module):\n",
    "\t\t# Iterate over all named parameters in the scripted module\n",
    "\t\tfor name, param in scripted_module.named_parameters(recurse=True):\n",
    "\t\t\t\t# Apply weight initialization\n",
    "\t\t\t\tif param.dim() > 1:\n",
    "\t\t\t\t\t\ttorch.nn.init.kaiming_uniform_(param, a=math.sqrt(5))\n",
    "\t\t\t\t# Apply bias initialization\n",
    "\t\t\t\telif param.dim() == 1:\n",
    "\t\t\t\t\t\tfan_in, _ = torch.nn.init._calculate_fan_in_and_fan_out(param.unsqueeze(0))\n",
    "\t\t\t\t\t\tbound = 1 / math.sqrt(fan_in)\n",
    "\t\t\t\t\t\ttorch.nn.init.uniform_(param, -bound, bound)\n",
    "\n",
    "\t\tfor name, buffer in scripted_module.named_buffers():\n",
    "\t\t\t\tif 'running_mean' in name or 'running_var' in name:\n",
    "\t\t\t\t\t\tbuffer.fill_(0 if 'mean' in name else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0697, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = [child for child in model2.children()]\n",
    "p = [param for param in c[0].parameters()]\n",
    "p[0][0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_scripted_module_parameters(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0486, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = [child for child in model.children()]\n",
    "children[0].weight[0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False),\n",
       " BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " Sequential()]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "children = [child for child in children[0].children()]\n",
    "children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'layers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[82], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m seq \u001b[38;5;241m=\u001b[39m children[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m \u001b[43mseq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Nico\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'layers'"
     ]
    }
   ],
   "source": [
    "seq = children[-1]\n",
    "seq.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspired by https://stackoverflow.com/a/77474877.\n",
    "# very hacky, don't love this solution\n",
    "def reinitialize(model):\n",
    "\t\tfor l in model.layers:\n",
    "\t\t\t\tif hasattr(l,'kernel_initializer'):\n",
    "\t\t\t\t\t\tif hasattr(l.kernel_initializer, 'seed'):\n",
    "\t\t\t\t\t\t\t\tl.kernel_initializer.__init__(seed=np.random.randint(1e6))\n",
    "\t\t\t\t\t\tl.kernel.assign(l.kernel_initializer(tf.shape(l.kernel)))\n",
    "\t\t\t\tif hasattr(l,'bias_initializer'):\n",
    "\t\t\t\t\t\tif hasattr(l.bias_initializer, 'seed'):\n",
    "\t\t\t\t\t\t\t\tl.bias_initializer.__init__(seed=np.random.randint(1e6))\n",
    "\t\t\t\t\t\tl.bias.assign(l.bias_initializer(tf.shape(l.bias)))\n",
    "\t\t\t\tif hasattr(l,'recurrent_initializer'):\n",
    "\t\t\t\t\t\tif hasattr(l.recurrent_initializer, 'seed'):\n",
    "\t\t\t\t\t\t\t\tl.recurrent_initializer.__init__(seed=np.random.randint(1e6))\n",
    "\t\t\t\t\t\tl.recurrent_kernel.assign(l.recurrent_initializer(tf.shape(l.recurrent_kernel)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.0018577129>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reinitialize(model)\n",
    "model.weights[0][0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_interfaces import ModelInterface, TensorFlowModel, TorchModel\n",
    "from model_garden import ModelGarden\n",
    "\n",
    "path = 'models/compiled.keras'\n",
    "file_path, file_extension = path.split('.')\n",
    "file_name = file_path.split('/')[-1]\n",
    "if file_extension == 'keras':\n",
    "\tcustom_model = TensorFlowModel.load_model(path)\n",
    "elif file_extension == 'pt':\n",
    "\tcustom_model = TorchModel.load_model(path)\n",
    "else:\n",
    "\traise ValueError(f'Unexpected file extension: {file_extension}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
