{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "waSGog8Kj9W5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pickle\n",
        "import numpy as np\n",
        "from os.path import exists\n",
        "from keras.datasets import cifar10\n",
        "from robustbench.utils import load_model\n",
        "from manifold_angles import ManifoldAngles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9D7yqJFJD0PU"
      },
      "outputs": [],
      "source": [
        "def get_model_predictions(model, data):\n",
        "  predictions = []\n",
        "  BATCH_SIZE = 50 # 50 seems to work, maybe try to increase\n",
        "\n",
        "  for i in range(0, data.shape[0], BATCH_SIZE):\n",
        "    print(f'BATCH: {i} to {i + BATCH_SIZE}')\n",
        "    input_slice = data[i : i + BATCH_SIZE].type(torch.FloatTensor).cuda()\n",
        "    output_slice = model(input_slice)\n",
        "    del input_slice\n",
        "\n",
        "    predictions.extend(output_slice.cpu().detach().numpy())\n",
        "    del output_slice\n",
        "\n",
        "  return np.array(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AFDILCPIB6hv"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "  'Wang2023Better_WRN-70-16',\n",
        "  'Wang2023Better_WRN-28-10',\n",
        "  'Rebuffi2021Fixing_70_16_cutmix_extra',\n",
        "  'Gowal2020Uncovering_extra',\n",
        "  'Rebuffi2021Fixing_70_16_cutmix_ddpm',\n",
        "  'Rebuffi2021Fixing_28_10_cutmix_ddpm',\n",
        "  'Sehwag2021Proxy',\n",
        "  'Rade2021Helper_R18_ddpm',\n",
        "  'Rebuffi2021Fixing_R18_cutmix_ddpm',\n",
        "  'Gowal2020Uncovering',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbYtzkbCCTzF",
        "outputId": "5e2dc222-dc1f-4685-d004-bcd03970f004"
      },
      "outputs": [],
      "source": [
        "for model_name in models:\n",
        "  print(f'Checking existing predictions for {model_name}')\n",
        "  predictions_path_name = f'./predictions/cifar_predictions_{model_name}'\n",
        "  if exists(predictions_path_name):\n",
        "    print(f'  Predictions for {model_name} already exists.')\n",
        "  else:\n",
        "    print(f'  Predictions for {model_name} not found.')\n",
        "    # load model into gpu\n",
        "    print('  Loading model...')\n",
        "    model = load_model(model_name=model_name, dataset='cifar10', threat_model='L2').cuda()\n",
        "    print('  Loading dataset...')\n",
        "    (cifar_X_train, _), (_, _) = cifar10.load_data()\n",
        "    del _ # don't save stuff we're not using\n",
        "    cifar_X_train = cifar_X_train / 255\n",
        "    model_inputs = torch.from_numpy(np.reshape(cifar_X_train, (cifar_X_train.shape[0], 3, 32, 32)))\n",
        "\n",
        "    print('  Generating predictions...')\n",
        "    predictions = get_model_predictions(model, model_inputs)\n",
        "    print('len predictions:', len(predictions))\n",
        "\n",
        "    print(f'  Saving predictions to {predictions_path_name}')\n",
        "    with open(predictions_path_name, 'wb') as file:\n",
        "      pickle.dump(predictions, file)\n",
        "      file.close()\n",
        "\n",
        "    # clean up\n",
        "    del model, cifar_X_train, model_inputs, predictions, file\n",
        "\n",
        "  print(f'Checking existing curvature sets for {model_name}')\n",
        "  curvatures_path_name = f'./output_curv/cifar_output_curv_{model_name}'\n",
        "  if exists(curvatures_path_name):\n",
        "    print(f'  Curvatures for {model_name} already exists.')\n",
        "  else:\n",
        "    print(f'  Curvatures for {model_name} not found.')\n",
        "    with open(predictions_path_name, 'rb') as file:\n",
        "      predictions = np.array(pickle.load(file))\n",
        "      file.close()\n",
        "\n",
        "    print('  Loading dataset...')\n",
        "    (_, cifar_train_y), (_, _) = cifar10.load_data()\n",
        "    del _, file # don't save stuff we're not using\n",
        "\n",
        "    curvatures = []\n",
        "    print('   Generating curvatures:')\n",
        "    for y_class in range(10):\n",
        "      print(f'     Generating curvature for class {y_class}...')\n",
        "      _, manifold_neighbour_angle_sum = ManifoldAngles([predictions[cifar_train_y[:, 0] == y_class]], classsize=1, neighboursize1=10, dim_reduc_size=5)\n",
        "      curvatures.append(np.array(manifold_neighbour_angle_sum))\n",
        "      del _, manifold_neighbour_angle_sum\n",
        "\n",
        "    print(f'  Saving curvatures to {curvatures_path_name}')\n",
        "    with open(curvatures_path_name, 'wb') as file:\n",
        "      pickle.dump(np.array(curvatures), file)\n",
        "      file.close()\n",
        "\n",
        "    # clean up\n",
        "    del predictions, cifar_train_y, curvatures, file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### save average to file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "curvs_list = []\n",
        "for model in models:\n",
        "  with open(f'./cached/output_curv/cifar_output_curv_{model}', 'rb') as file:\n",
        "    curvs_list.append(pickle.load(file))\n",
        "    file.close()\n",
        "\n",
        "averages = np.average(curvs_list, axis=0)\n",
        "with open(f'./cached/output_curv/cifar_output_curv_AVG', 'wb') as file:\n",
        "  pickle.dump(averages, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 5000)\n"
          ]
        }
      ],
      "source": [
        "with open(f'./cached/cifar_input_curv', 'rb') as file:\n",
        "  input_curv = np.array(pickle.load(file)).squeeze()\n",
        "  file.close()\n",
        "\n",
        "print(input_curv.shape)\n",
        "\n",
        "with open(f'./cached/cifar_input_curv_ndarray', 'wb') as file:\n",
        "  pickle.dump(input_curv, file)\n",
        "  file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 5000)\n"
          ]
        }
      ],
      "source": [
        "with open(f'./cached/cifar_input_curv_ndarray', 'rb') as file:\n",
        "  input_curv_new = pickle.load(file)\n",
        "  print(input_curv_new.shape)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
