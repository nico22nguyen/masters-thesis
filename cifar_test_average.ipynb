{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyFBQu7lnwPJ"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "D6VETkSHnwPM"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.datasets import cifar10  #\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.layers import Dense, Conv2D, Flatten\n",
        "import keras.utils as np_utils\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBzB3AhynwPN"
      },
      "source": [
        "## Define classes and functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "45Tk-1tUnwPO"
      },
      "outputs": [],
      "source": [
        "class LayerCharacteristics():\n",
        "  def __init__(self):\n",
        "    self.space_linearity_sum = []\n",
        "    self.total_sum = []\n",
        "    self.svd_weights = {}\n",
        "    self.distances = {}\n",
        "    self.neighbour_dict = {}\n",
        "    self.U_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "a6iK6AX2nwPR"
      },
      "outputs": [],
      "source": [
        "def ManifoldAngles(layerfeatlist,neighboursize1=10,classsize=10,dim_reduc_size=3,fileloc = \"layers/\"):\n",
        "  starttime = tf.timestamp()\n",
        "  tf.print(\"start: \")\n",
        "\n",
        "  no_of_layers = len(layerfeatlist)\n",
        "  reduction_quality = []\n",
        "  class_chars = []\n",
        "\n",
        "  for c1 in range(classsize):\n",
        "    class_chars.append([])\n",
        "    for layer_i in range(no_of_layers):\n",
        "      class_chars[c1].append(LayerCharacteristics())\n",
        "      layer_features = layerfeatlist[layer_i]\n",
        "\n",
        "      layer_start = tf.timestamp()\n",
        "\n",
        "      for i,x_i in enumerate(layer_features):\n",
        "\n",
        "        class_chars[c1][layer_i].neighbour_dict[i] = tf.argsort(tf.norm( tf.math.subtract(layer_features,x_i) ,axis=1))[0:neighboursize1+1]\n",
        "\n",
        "        W_i = tf.gather(layer_features,class_chars[c1][0].neighbour_dict[i])\n",
        "\n",
        "        W_i = ( W_i - tf.math.reduce_mean(W_i,axis=0) )\n",
        "        s, u, v = tf.linalg.svd( W_i )\n",
        "        W_i_reduced = v[:,:dim_reduc_size]\n",
        "\n",
        "        class_chars[c1][layer_i].svd_weights[i] = s[:dim_reduc_size]\n",
        "        reduction_quality.append(  tf.reduce_sum( (s[:dim_reduc_size])/ tf.reduce_sum(s) ) )\n",
        "        class_chars[c1][layer_i].U_dict[i] = W_i_reduced\n",
        "\n",
        "      tf.print(\"--layer time: \", tf.timestamp() - layer_start)\n",
        "      class_chars[c1][layer_i].space_linearity_sum = 0.0\n",
        "      angle_start = tf.timestamp()\n",
        "\n",
        "      manifold_neighbour_angle_sum=[]\n",
        "      for i in range(len(class_chars[c1][layer_i].U_dict)):\n",
        "        manifold_neighbour_angle_sum_temp=[]\n",
        "        manifold_neighbour_angle_sum.append([])\n",
        "\n",
        "        for j in class_chars[c1][0].neighbour_dict[i]:\n",
        "          if i != j:\n",
        "            teta =  tf.matmul(  tf.transpose(class_chars[c1][layer_i].U_dict[i]),  class_chars[c1][layer_i].U_dict[int(j)]   )\n",
        "            weights =  tf.matmul(  tf.transpose( tf.expand_dims(class_chars[c1][layer_i].svd_weights[i],0)), tf.expand_dims(class_chars[c1][layer_i].svd_weights[int(j)],0)  )\n",
        "            Q = teta*weights\n",
        "\n",
        "            s, u, v = tf.linalg.svd( Q )\n",
        "\n",
        "            tetaw = tf.reduce_sum(s)/tf.linalg.trace(weights)\n",
        "            angles = tf.math.acos( tf.clip_by_value(tetaw,-1,1) )\n",
        "            manifold_neighbour_angle_sum_temp.append( tf.math.sin(angles)  )\n",
        "\n",
        "        manifold_neighbour_angle_sum[i].append(tf.reduce_mean(tf.convert_to_tensor(manifold_neighbour_angle_sum_temp)))\n",
        "      class_chars[c1][layer_i].space_linearity_sum = tf.reduce_mean( tf.convert_to_tensor(manifold_neighbour_angle_sum ))\n",
        "      tf.print(\"--angle time: \", tf.timestamp() - angle_start)\n",
        "\n",
        "  if no_of_layers==1: tf.print(\"Average reduction quality: \",  tf.reduce_mean(reduction_quality))\n",
        "  tf.print(\"endtime: \", tf.timestamp() - starttime)\n",
        "  return class_chars,manifold_neighbour_angle_sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CafHGN1mnwPa"
      },
      "outputs": [],
      "source": [
        "def shuffle_data(X: np.ndarray, Y: np.ndarray, seed: int):\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(X)\n",
        "  np.random.seed(seed)\n",
        "  np.random.shuffle(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P92br6R9nwPa"
      },
      "outputs": [],
      "source": [
        "def get_reduced_datasets(data_size: int, X: np.ndarray, Y: np.ndarray, order_method: str, curvature_set='input', dataset='mnist'):\n",
        "\n",
        "  _input_curvatures = cifar_input_curvature\n",
        "  _output_curvatures = cifar_output_class_curvatures\n",
        "  _train_y = cifar_train_y[:, 0]\n",
        "\n",
        "  _curvature_set = _input_curvatures if curvature_set == 'input' else _output_curvatures\n",
        "\n",
        "  for y_class in range(10):\n",
        "    class_indices = _train_y == y_class\n",
        "    keep_indices = None\n",
        "    if order_method == 'random':\n",
        "      keep_indices = np.random.choice(X[class_indices].shape[0], data_size, replace=True)\n",
        "    elif order_method == 'low_to_high':\n",
        "      keep_indices = np.argsort(_curvature_set[y_class][:, 0])[:data_size]\n",
        "    elif order_method == 'high_to_low':\n",
        "      keep_indices = np.argsort(_curvature_set[y_class][:, 0])[-data_size:]\n",
        "    elif order_method == 'mid':\n",
        "      num_low_curv = data_size // 2\n",
        "      num_high_curv = data_size - num_low_curv\n",
        "\n",
        "      curv_midpoint = _curvature_set[y_class][:, 0].shape[0] // 2\n",
        "\n",
        "      keep_indices = np.argsort(_curvature_set[y_class][:, 0])[curv_midpoint - num_low_curv : curv_midpoint + num_high_curv]\n",
        "    elif order_method == 'ratio_low_to_high':\n",
        "      ratios = _output_curvatures[y_class][:, 0] / _input_curvatures[y_class][:, 0]\n",
        "      keep_indices = np.argsort(ratios)[:data_size]\n",
        "    elif order_method == 'ratio_high_to_low':\n",
        "      ratios = _output_curvatures[y_class][:, 0] / _input_curvatures[y_class][:, 0]\n",
        "      keep_indices = np.argsort(ratios)[-data_size:]\n",
        "    else:\n",
        "      raise ValueError(f\"order method not implemented: {order_method}\")\n",
        "\n",
        "    new_x_row = X[class_indices][keep_indices]\n",
        "    new_y_row = Y[class_indices][keep_indices]\n",
        "\n",
        "    Reduced_X = np.vstack([Reduced_X, new_x_row]) if y_class > 0 else new_x_row\n",
        "    Reduced_Y = np.vstack([Reduced_Y, new_y_row]) if y_class > 0 else new_y_row\n",
        "\n",
        "  return Reduced_X, Reduced_Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qbGcqgt1nwPb"
      },
      "outputs": [],
      "source": [
        "def get_accuracies(X_train, Y_train, X_test, Y_test, order_method='low_to_high', curvature_set='input', num_models=5, shuffle_seed=None, dataset='mnist'):\n",
        "  valacclist = []\n",
        "  acclist = []\n",
        "  for data_size in datasizes:\n",
        "    Reduced_X_train, Reduced_Y_train = get_reduced_datasets(data_size, X_train, Y_train, order_method, curvature_set, dataset=dataset)\n",
        "    print(f'ReducedX.shape: {Reduced_X_train.shape}')\n",
        "\n",
        "    if shuffle_seed is not None:\n",
        "      shuffle_data(Reduced_X_train, Reduced_Y_train, shuffle_seed)\n",
        "\n",
        "    valacclist.append([])\n",
        "    acclist.append([])\n",
        "    for _ in range(num_models):\n",
        "      nt = create_cifar_model()\n",
        "      nt.compile(loss= tf.keras.losses.CategoricalCrossentropy(), optimizer='adam', metrics=['categorical_accuracy'])\n",
        "      history = nt.fit(Reduced_X_train, Reduced_Y_train, epochs=20, validation_data=(X_test, Y_test), verbose=0, batch_size = 128)\n",
        "      del nt\n",
        "      print(f\"  train acc = {history.history['categorical_accuracy'][-1]} val acc = {history.history['val_categorical_accuracy'][-1]}\")\n",
        "      valacclist[-1].append(history.history['val_categorical_accuracy'][-1])\n",
        "      acclist[-1].append(history.history['categorical_accuracy'][-1])\n",
        "      del history\n",
        "\n",
        "  return valacclist, acclist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YXHsBa-mnwPb"
      },
      "outputs": [],
      "source": [
        "def plot_accuracies(accuracies, names=None):\n",
        "  plt.figure(figsize=(14, 10))\n",
        "  for acclist in accuracies:\n",
        "    plt.plot(datasizes, np.mean(acclist, axis=1))\n",
        "\n",
        "  if names is not None:\n",
        "    plt.legend(names, fontsize=11)\n",
        "\n",
        "  plt.xscale('log')\n",
        "  plt.gca().invert_xaxis()\n",
        "  plt.grid()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL94GPQanwQE"
      },
      "source": [
        "# cifar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "K_xA3ZBhnwQE"
      },
      "outputs": [],
      "source": [
        "(cifar_X_train, cifar_train_y), (cifar_X_test, cifar_test_y) = cifar10.load_data()\n",
        "cifar_X_train = cifar_X_train / 255\n",
        "cifar_X_test = cifar_X_test/ 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "AHf7OI1rnwQF"
      },
      "outputs": [],
      "source": [
        "cifar_Y_train = np_utils.to_categorical(cifar_train_y, 10)\n",
        "cifar_Y_test = np_utils.to_categorical(cifar_test_y, 10)\n",
        "\n",
        "del cifar_test_y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "NnSYXW47nwQF"
      },
      "outputs": [],
      "source": [
        "def create_cifar_model():\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, 3, padding='same', input_shape=cifar_X_train.shape[1:], activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, 3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(10, activation='softmax'),\n",
        "  ])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uZM_10oxnwQH"
      },
      "outputs": [],
      "source": [
        "filenames = [\n",
        "  'Wang2023Better_WRN-70-16',\n",
        "  'Wang2023Better_WRN-28-10',\n",
        "  'Rebuffi2021Fixing_70_16_cutmix_extra',\n",
        "  'Gowal2020Uncovering_extra',\n",
        "]\n",
        "\n",
        "curvatures = []\n",
        "for filename in filenames:\n",
        "  with open(f'./output_curv/cifar_output_curv_{filename}', 'rb') as file:\n",
        "    curvatures.append(pickle.load(file))\n",
        "\n",
        "curvatures = np.array(curvatures)\n",
        "curvatures.shape\n",
        "\n",
        "del file, filename, filenames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PwtAYNu0nwQH"
      },
      "outputs": [],
      "source": [
        "# define curvatures list\n",
        "cifar_output_class_curvatures = np.average(curvatures, axis=0)\n",
        "del curvatures"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('cifar_input_curv', 'rb') as file:\n",
        "  cifar_input_curvature = np.array(pickle.load(file))\n",
        "\n",
        "del file"
      ],
      "metadata": {
        "id": "W3zsHd80r1Uz"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N0dUlnoRnwQI"
      },
      "outputs": [],
      "source": [
        "datasizes = np.logspace(3.699, 1.899, 20).astype('int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J51T8NZinwQI",
        "outputId": "682c984f-bf2e-4c9c-d764-675590e1d0e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ReducedX.shape: (50000, 32, 32, 3)\n"
          ]
        }
      ],
      "source": [
        "# these take a while to train, so I'm breaking them into their own cells to avoid retraining all of them if changes need to be mande to just one\n",
        "# only gets through second datasize so far\n",
        "rand, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUyGfB8gnwQJ"
      },
      "outputs": [],
      "source": [
        "ratio_low, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_low_to_high')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ratio_high, _ = get_accuracies(cifar_X_train, cifar_Y_train, cifar_X_test, cifar_Y_test, order_method='ratio_high_to_low')"
      ],
      "metadata": {
        "id": "CREgKdjntZdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aZJPuhenwQJ"
      },
      "outputs": [],
      "source": [
        "plot_accuracies([rand, ratio_low, ratio_high], ['rand', 'ratio low', 'ratio high'])"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}